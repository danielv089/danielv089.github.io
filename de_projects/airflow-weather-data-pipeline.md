---
layout: default
title: Airflow Weather Data Pipeline
parent: Projects
nav_order: 1
---

# From API to Database: Dockerized Airflow ETL Pipeline for Weather Data
```
  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
```

## ğŸ“Œ Overview
This project implements an ETL pipeline to fetch weather data from the OpenWeather API about main Polish cities, transform it and load the processed data into a PostgreSQL database. 

The pipeline is orchestrated with Apache Airflow, which allows scheduled execution each step of the pipeline. 

The entire workflow is containerized and deployed using a multi-container Docker Compose setup ensuring easy reproducibility, scalability, and isolation of services such as Airflow, PostgreSQL and supporting components.

The purpose of this project is to build a fully automated ETL pipeline for weather data using Apache Airflow for orchestration and Docker for containerized deployment. 

![data_architecture](/docs/weather_data_architecture.jpg)


## âš™ï¸ DAGs Overview
The setup consists of two DAGs:

- **weather_data_db** â€“ Responsible for setting up the PostgreSQL backend database, creating separate schemas(staging and core), and creating the tables needed for both the staging step and the final database.

- **weather_data_etl** â€“ The full ETL process: checking the OpenWeather API, extracting weather data for multiple Polish cities, transforming it into structured DataFrames, and loading it into both staging and core tables.

### âš™ï¸ weather_data_db â€“ Database Setup DAG

The db DAG scheduled to run every day before the main ETL pipeline to ensure an existing backend for the ETL pipeline properly initialized and to facilitate easier schema modifications.

- Create Database â€“ poland_weather_db if it doesnâ€™t exist.
- Create Schemas â€“ staging and core.
- Create Tables â€“ Staging tables and core tables.

![db_dag](/docs/weather_db.png)

### âš™ï¸ weather_data_etl â€“ ETL Pipeline DAG

The main ETL DAG scheduled to run every day at 6:00 CET. Extract, transform, and load weather data into the database. The dag leverages  TaskFlow API, dynamic task mapping and XCOMs to pass data between tasks.

- API Check â€“ Verify OpenWeather API availability.
- Extract Data â€“ Extracts weather data.
- Combine Data â€“ Combining datasets of separate cities into one file.
- Transform Data â€“ Process JSON into DataFrames: df_dim_city, df_dim_weather_desc, df_fact_weather.
- Load to Staging â€“ Load CSV data into staging tables.
- Load to Core â€“ Populate core tables from staging.
- Clean Staging â€“ Truncate staging tables after successful ETL run.

![etl_dag_1](/docs/weather_etl_1.png)

![etl_dag_2](/docs/weather_etl_2.png)

## â–¶ï¸ How to Run

Clone the repository and navigate into it

```
git clone <repo-url>
cd <project-directory>
```
Create necessary folders for Airflow

```
mkdir -p ./logs ./plugins ./config
```
Create Airflow user ID

```
echo -e "AIRFLOW_UID=$(id -u)" > .env
```
Start the Airflow environment with Docker Compose

```
docker compose up -d --build
```
Access the Airflow Web UI via  http://localhost:8080 in your browser. 

Default Credentials:

Username: airflow

Password: airflow

Additionally, set up an Airflow Variable called open_weather_api through the Airflow Web UI to store your OpenWeather API key and create two Airflow connections in the Web UI: postgres_conn to access the main PostgreSQL DB and postgres_weather_db for the weather database.

## ğŸ—ƒï¸ ERD Diagram

![poland_weather_db](/docs/poland_weather_db.jpg)

## ğŸ§° Tech Stack

- **Docker and Docker Compose**
- **Apache Airflow 3.0.3**
- **PostgreSQL**
- **Python**
- **Pandas**
- **SQL**

## ğŸ“ Repository Structure

```
â”œâ”€â”€ dags
â”‚   â”œâ”€â”€ weather_db.py
â”‚   â””â”€â”€ weather.py
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ df_dim_city.csv
â”‚   â”œâ”€â”€ df_dim_weather_desc.csv
â”‚   â””â”€â”€ df_fact_weather.csv
â”œâ”€â”€ docker-compose.yaml
â”œâ”€â”€ docs
â”‚   â”œâ”€â”€ poland_weather_db.jpg
â”‚   â”œâ”€â”€ weather_data_architecture.jpg
â”‚   â”œâ”€â”€ weather_db.png
â”‚   â”œâ”€â”€ weather_etl_1.png
â”‚   â””â”€â”€ weather_etl_2.png
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â””â”€â”€ src
    â”œâ”€â”€ check_api.py
    â”œâ”€â”€ create_weather_db.py
    â”œâ”€â”€ extract_data.py
    â”œâ”€â”€ __init__.py
    â””â”€â”€ transform_data.py
```

## ğŸ”— References

- Docker 
https://docs.docker.com/

- Apache Airflow
https://airflow.apache.org/

- PostgreSQL
https://airflow.apache.org/docs/

- Python
https://www.python.org/doc/